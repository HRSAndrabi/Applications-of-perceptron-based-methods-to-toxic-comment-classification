% Abstract
Interactions occurring online are typically anonymous, and insensitive to the threat of social accountability for toxic behaviour. This leads to the employment of abusive, and anti-social tactics that go far beyond what might be considered acceptable in face-to-face settings. Machine learning techniques present various methods for automatic detection and classification of such toxic behaviour. While the practical effectiveness of such techniques is well-studied, it has proven difficult to occlude biases in the training datasets from flowing onwards to the classifier, and thereafter contributing to discriminatory classifications against sensitive classes such as race, religion, and gender. In this note, I seek to illuminate the capacity for word-embedding techniques to suppress undue learning of sensitive biases in training datasets. I demonstrate that [...]

% While anonymity of online social interactions alone is not sufficient to solely induce anti-social or abusive behaviour, it promotes insular attitudes and the employment of tactics that go far beyond what might be employed in face-to-face settings.