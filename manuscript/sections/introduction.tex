% Introduction

The rise of the internet has transformed the primary setting of our social interactions to one which promotes extreme behaviours and dispenses fewer consequences.
Ours is the age of cyberspace: now, more than ever before, individuals possess an unrestrained freedom to express their opinions for all to behold. 
This new setting does not reprimand us when we express opinions anarchically and without requisition.
Instead, it promotes tendentious behaviour that is insular to empathetic considerations.
It is against this contextual background that the majority of modern social interactions transpire --- social interactions that exploit, by and large, the traceable anonymity of online systems and the resulting protection against social accountability. 
Indeed, moderation of online interactions is crucial to maintaining positive and healthy discussions. 
Naturally, this raises an important question: how do we efficiently and effectively evaluate the vast and inexorable flow of online interactions to limit proliferation of abusive and anti-social behaviour?

Given these analytical problems and the impending social importance of developing measures to promote healthy online interactions, the analysis in this note will empirically examine the mitigating capacity of machine-learning techniques to identify and filter out textual instances of toxic behaviour.
To this end, I focus my analysis on the assessment of the joint classification capacity of: (1) a range popular of machine-learning techniques; and, (2) a suite of text-embedding representations. 
In particular, I consider the capacity of these model-embedding representations to minimise incidence of biased classifications: that is, the erroneous tendency for discriminatory classification against sensitive classes such as race, religion, and gender.


% In general, incidences of extreme behaviour are enabled by two critical features of online systems: (1) traceable anonymity; and (2) visual anonymity. 
% The former refers to the inability of agents to be held to account for offensive behaviour due to time and resource constraints associated with tracing offending online activities back to the originator in the physical world.
% As a result, we observe in online interactions a greater tendency for employment of abusive and anti-social tactics that go far beyond what might be considered acceptable in face-to-face setting.

% insensitive to the threat of social accountability for offensive behaviour. While anonymity alone is not sufficient to solely induce anti-social or abusive behaviour, it promotes insular tactics or language that go far beyond what might be employed in soci

% the corresponding lack of social accountability encourages insular, and often impolite behaviour, as well as the employment of tactics or language that go far beyond social expectations of reasonable behaviour in face-to-face-interaction.

% The mechanism of social accountability for one's behaviour is critical to moderating one's inclination towards abusive or anti-social behaviour. 

% In face-to-face interactions, we are 

% Online social interactions are exempt from the that come with the social accountability of face-to-face interaction.

% Where abusive or anti-social behaviour would be moderated in circumstances of physical social interaction 


% Online social interactions are relatively exempt from the influence of social accountability present in face-to-face social interaction, which serves to moderate one's inclination to engage in abusive or anti-social behaviour.

% In face-to-face social interactions, the immediate social accountability engendered by physical proximity serves to moderate one's inclination to engage in abusive or anti-social behaviour.

% Face-to-face social interactions are characterised by a particular quality of social accountability


% Online interactions are not governed by the same social pressures of face-to-face interactions.

% In contrast to physical social interactions, online social interactions are not regulated by the threat of immediate social accountability for anti-social and abusive behaviour. 


% In online social interactions, one's tendency towards anti-social or abusive behaviour is not moderated by the threat of immediate social accountability that supervises our face-to-face interactions.


% In contrast to face-to-face interactions, tendencies towards anti-social and abusive behaviour in online social interactions are comparatively unfettered by the threat of immediate social accountability. While anonymity alone is not sufficient to solely induce anti-social or abusive behaviour, the corresponding lack of social accountability encourages insular, and often impolite behaviour, as well as the employment of tactics or language that go far beyond social expectations of reasonable behaviour in face-to-face-interaction.


% In contrast to face-to-face interaction, interactions occurring online are typically anonymous, and insensitive to the threat of social accountability for offensive behaviour. While anonymity alone is not sufficient to solely induce anti-social or abusive behaviour, the corresponding lack of social accountability encourages insular, and often impolite behaviour, as well as the employment of tactics or language that go far beyond social expectations of reasonable behaviour in face-to-face-interaction.


% The lack of accountability in online social interactions encourages insular behaviour, and the employment of tactics that go far beyond that which might be employed in face-to-face interaction.